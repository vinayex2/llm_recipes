{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchao\n",
      "  Downloading torchao-0.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting torchtune\n",
      "  Downloading torchtune-0.3.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from torchao) (2.4.1+cu124)\n",
      "Requirement already satisfied: numpy in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from torchao) (1.26.3)\n",
      "Collecting sentencepiece (from torchao)\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from torchao) (24.1)\n",
      "Collecting datasets (from torchtune)\n",
      "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from torchtune) (0.24.6)\n",
      "Requirement already satisfied: safetensors in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from torchtune) (0.4.5)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from torchtune) (0.7.0)\n",
      "Collecting blobfile>=2 (from torchtune)\n",
      "  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from torchtune) (4.66.5)\n",
      "Collecting omegaconf (from torchtune)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pycryptodomex>=3.8 (from blobfile>=2->torchtune)\n",
      "  Downloading pycryptodomex-3.20.0-cp35-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from blobfile>=2->torchtune) (2.2.2)\n",
      "Collecting lxml>=4.9 (from blobfile>=2->torchtune)\n",
      "  Downloading lxml-5.3.0-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: filelock>=3.0 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from blobfile>=2->torchtune) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from datasets->torchtune) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->torchtune)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from datasets->torchtune) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from datasets->torchtune) (2.32.3)\n",
      "Collecting xxhash (from datasets->torchtune)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess (from datasets->torchtune)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->torchtune) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from datasets->torchtune) (3.10.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from datasets->torchtune) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from huggingface-hub->torchtune) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from tqdm->torchtune) (0.4.6)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->torchtune)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from tiktoken->torchtune) (2024.7.24)\n",
      "Requirement already satisfied: sympy in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from torch->torchao) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from torch->torchao) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from torch->torchao) (3.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets->torchtune) (2.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets->torchtune) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets->torchtune) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets->torchtune) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets->torchtune) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from aiohttp->datasets->torchtune) (1.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from requests>=2.32.2->datasets->torchtune) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from requests>=2.32.2->datasets->torchtune) (3.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from requests>=2.32.2->datasets->torchtune) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from jinja2->torch->torchao) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from pandas->datasets->torchtune) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from pandas->datasets->torchtune) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from pandas->datasets->torchtune) (2024.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from sympy->torch->torchao) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->torchtune) (1.16.0)\n",
      "Downloading torchao-0.1-py3-none-any.whl (54 kB)\n",
      "Downloading torchtune-0.3.0-py3-none-any.whl (514 kB)\n",
      "Downloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
      "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 991.5/991.5 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading lxml-5.3.0-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 7.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.4/3.8 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.7/3.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 5.8 MB/s eta 0:00:00\n",
      "Downloading pycryptodomex-3.20.0-cp35-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.0/1.8 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144577 sha256=d5c121a3fc25aad7b8298fd88098d337d8fbbd30ccdcb98b6e017a6820ee179e\n",
      "  Stored in directory: c:\\users\\whitebox\\appdata\\local\\pip\\cache\\wheels\\1a\\97\\32\\461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: sentencepiece, antlr4-python3-runtime, xxhash, pycryptodomex, omegaconf, lxml, dill, multiprocess, blobfile, torchao, datasets, torchtune\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 blobfile-3.0.0 datasets-3.0.1 dill-0.3.8 lxml-5.3.0 multiprocess-0.70.16 omegaconf-2.3.0 pycryptodomex-3.20.0 sentencepiece-0.2.0 torchao-0.1 torchtune-0.3.0 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "# Install stable PyTorch, torchvision, torchao stable releases\n",
    "# pip install torch torchvision \n",
    "!pip install torchao torchtune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tune [-h] {download,ls,cp,run,validate} ...\n",
      "\n",
      "Welcome to the torchtune CLI!\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "\n",
      "subcommands:\n",
      "  {download,ls,cp,run,validate}\n",
      "    download            Download a model from the Hugging Face Hub.\n",
      "    ls                  List all built-in recipes and configs\n",
      "    cp                  Copy a built-in recipe or config to a local path.\n",
      "    run                 Run a recipe. For distributed recipes, this supports\n",
      "                        all torchrun arguments.\n",
      "    validate            Validate a config and ensure that it is well-formed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0928 20:44:03.514000 14620 torch\\distributed\\elastic\\multiprocessing\\redirects.py:28] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "!tune -help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring files matching the following patterns: *.safetensors\n",
      "Successfully downloaded model repo and wrote to the following locations:\n",
      "C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\llm_recipes\\Llama-3.2-1B-Instruct\\.cache\n",
      "C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\llm_recipes\\Llama-3.2-1B-Instruct\\.gitattributes\n",
      "C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\llm_recipes\\Llama-3.2-1B-Instruct\\config.json\n",
      "C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\llm_recipes\\Llama-3.2-1B-Instruct\\generation_config.json\n",
      "C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\llm_recipes\\Llama-3.2-1B-Instruct\\LICENSE.txt\n",
      "C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\llm_recipes\\Llama-3.2-1B-Instruct\\original\n",
      "C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\llm_recipes\\Llama-3.2-1B-Instruct\\README.md\n",
      "C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\llm_recipes\\Llama-3.2-1B-Instruct\\special_tokens_map.json\n",
      "C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\llm_recipes\\Llama-3.2-1B-Instruct\\tokenizer.json\n",
      "C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\llm_recipes\\Llama-3.2-1B-Instruct\\tokenizer_config.json\n",
      "C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\llm_recipes\\Llama-3.2-1B-Instruct\\USE_POLICY.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0928 21:11:31.831000 13740 torch\\distributed\\elastic\\multiprocessing\\redirects.py:28] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "\n",
      "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]\n",
      "Fetching 12 files:   8%|▊         | 1/12 [00:01<00:11,  1.01s/it]\n",
      "Fetching 12 files:  25%|██▌       | 3/12 [00:10<00:35,  3.93s/it]\n",
      "Fetching 12 files:  58%|█████▊    | 7/12 [07:09<06:01, 72.25s/it]\n",
      "Fetching 12 files: 100%|██████████| 12/12 [07:09<00:00, 35.76s/it]\n"
     ]
    }
   ],
   "source": [
    "!tune download meta-llama/Llama-3.2-1B-Instruct --output-dir ./Llama-3.2-1B-Instruct --hf-token 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"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/torchtune/main/basics/instruct_datasets.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary entry point for fine-tuning with instruct datasets in torchtune is the instruct_dataset() builder. This lets you specify a local or Hugging Face dataset that follows the [instruct data](https://pytorch.org/torchtune/main/generated/torchtune.datasets.instruct_dataset.html#torchtune.datasets.instruct_dataset) format directly from the config and train your LLM on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtune.data import PromptTemplate, Message\n",
    "template_dict = {\n",
    "'system': (\"|begin_of_text|><|start_header_id|>system<|end_header_id|>\",\"\\n\"),\n",
    "    'assistant': (\"Below is an instruction that describes a task. Write a response that appropriately completes the request.<|eot_id|><|start_header_id|>user<|end_header_id|>\",\"\\n\"),\n",
    "    'user': (\"\",\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\"),\n",
    "}\n",
    "template = PromptTemplate(template_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtune.models.gemma import gemma_tokenizer\n",
    "g_tokenizer = gemma_tokenizer(\"gemma_tokenizer/tokenizer.model\",\n",
    "                            #   prompt_template=template_dict\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['instruction', 'input', 'output', 'prompt', 'instruction_input'],\n",
      "    num_rows: 121959\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c06ef14aa1e4785a686a0173a373f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/122 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "183489514"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# https://huggingface.co/docs/datasets/process\n",
    "\n",
    "ds = load_dataset(\"iamtarun/code_instructions_120k_alpaca\",split='train')\n",
    "\n",
    "# Define a function to compute the new column\n",
    "def add_columns(example):\n",
    "    example[\"instruction_input\"] = example[\"instruction\"] + ' ' +example[\"input\"]  # Modify as needed\n",
    "    return example\n",
    "\n",
    "# Apply the function to create the new column\n",
    "dataset = ds.map(add_columns)\n",
    "\n",
    "# Check the updated dataset\n",
    "print(dataset)\n",
    "\n",
    "\n",
    "dataset.to_json(\"custom_dataset.json\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In code\n",
    "from torchtune.models.gemma import gemma_tokenizer\n",
    "from torchtune.datasets import instruct_dataset\n",
    "\n",
    "ds = instruct_dataset(\n",
    "    tokenizer=g_tokenizer,\n",
    "    source=\"json\",\n",
    "    data_files=\"custom_dataset.json\",\n",
    "    split=\"train\",\n",
    "    train_on_input=True,\n",
    "    new_system_prompt=\"Below is an instruction that describes a task. Write a response that appropriately completes the request. \",\n",
    "    column_map = {\"input\": \"instruction_input\", \"output\": \"output\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.Create a function to calculate the sum of a sequence of integers. [1, 2, 3, 4, 5]# Python code\n",
      "def sum_sequence(sequence):\n",
      "  sum = 0\n",
      "  for num in sequence:\n",
      "    sum += num\n",
      "  return sum\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 235345, 21237, 3409, 108, 1293, 2707, 235298, 22170, 235278, 22170, 1245, 108, 139, 1882, 589, 235248, 235276, 108, 139, 746, 4507, 575, 10629, 235292, 108, 141, 1882, 2770, 4507, 108, 139, 773, 2707, 1]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dict = ds[0]\n",
    "tokens, labels = tokenized_dict[\"tokens\"], tokenized_dict[\"labels\"]\n",
    "print(g_tokenizer.decode(tokens))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0929 11:31:42.312000 10044 torch\\distributed\\elastic\\multiprocessing\\redirects.py:28] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\envs\\gpu_env\\Scripts\\tune.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\envs\\gpu_env\\Lib\\site-packages\\torchtune\\_cli\\tune.py\", line 49, in main\n",
      "    parser.run(args)\n",
      "  File \"C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\envs\\gpu_env\\Lib\\site-packages\\torchtune\\_cli\\tune.py\", line 43, in run\n",
      "    args.func(args)\n",
      "  File \"C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\envs\\gpu_env\\Lib\\site-packages\\torchtune\\_cli\\run.py\", line 185, in _run_cmd\n",
      "    self._run_single_device(args)\n",
      "  File \"C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\envs\\gpu_env\\Lib\\site-packages\\torchtune\\_cli\\run.py\", line 94, in _run_single_device\n",
      "    runpy.run_path(str(args.recipe), run_name=\"__main__\")\n",
      "  File \"<frozen runpy>\", line 291, in run_path\n",
      "  File \"<frozen runpy>\", line 98, in _run_module_code\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\envs\\gpu_env\\Lib\\site-packages\\recipes\\full_finetune_distributed.py\", line 22, in <module>\n",
      "    from torchtune import config, modules, training, utils\n",
      "  File \"C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\envs\\gpu_env\\Lib\\site-packages\\torchtune\\training\\__init__.py\", line 67, in <module>\n",
      "    from torchtune.training.quantization import get_quantizer_mode\n",
      "  File \"C:\\Users\\whitebox\\Desktop\\envs_and_git_repos\\envs\\gpu_env\\Lib\\site-packages\\torchtune\\training\\quantization.py\", line 25, in <module>\n",
      "    from torchao.quantization.prototype.qat import (\n",
      "ModuleNotFoundError: No module named 'torchao.quantization.prototype'\n"
     ]
    }
   ],
   "source": [
    "!tune run full_finetune_distributed --config ./torchtune.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
