{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub[cli,torch] in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (0.24.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from huggingface_hub[cli,torch]) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from huggingface_hub[cli,torch]) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from huggingface_hub[cli,torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from huggingface_hub[cli,torch]) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from huggingface_hub[cli,torch]) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from huggingface_hub[cli,torch]) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from huggingface_hub[cli,torch]) (4.9.0)\n",
      "Collecting InquirerPy==0.3.4 (from huggingface_hub[cli,torch])\n",
      "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from huggingface_hub[cli,torch]) (2.4.1+cu124)\n",
      "Requirement already satisfied: safetensors[torch] in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from huggingface_hub[cli,torch]) (0.4.5)\n",
      "Collecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface_hub[cli,torch])\n",
      "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from InquirerPy==0.3.4->huggingface_hub[cli,torch]) (3.0.47)\n",
      "Requirement already satisfied: colorama in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub[cli,torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from requests->huggingface_hub[cli,torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from requests->huggingface_hub[cli,torch]) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from requests->huggingface_hub[cli,torch]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from requests->huggingface_hub[cli,torch]) (2024.8.30)\n",
      "Requirement already satisfied: sympy in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from torch->huggingface_hub[cli,torch]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from torch->huggingface_hub[cli,torch]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from torch->huggingface_hub[cli,torch]) (3.1.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli,torch]) (0.2.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from jinja2->torch->huggingface_hub[cli,torch]) (2.1.5)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from safetensors[torch]->huggingface_hub[cli,torch]) (1.26.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\whitebox\\desktop\\envs_and_git_repos\\envs\\gpu_env\\lib\\site-packages (from sympy->torch->huggingface_hub[cli,torch]) (1.3.0)\n",
      "Downloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
      "Downloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
      "Installing collected packages: pfzy, InquirerPy\n",
      "Successfully installed InquirerPy-0.3.4 pfzy-0.3.4\n"
     ]
    }
   ],
   "source": [
    "!pip install jupyter transformers huggingface_hub[cli,torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "token='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\whitebox\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login('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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7383aa0515104bc2a2a46a81db9af31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe280ba93c8a45a59491e8bffde6722a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b168fb070d74cf49a319b9220ac2ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "USE_POLICY.md:   0%|          | 0.00/4.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a216b3bdad5a46eaae01d672067ce1f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed02229078d4477b8c4fb720be3bde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195e66ac38f644dfafdffb8b8fd68018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d229f658d54282a359ef59eaafef37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Responsible-Use-Guide.pdf:   0%|          | 0.00/1.25M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b30e3e913024a09bb7d1309ccf111bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a406c83646459cb603e87220e4ec7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a28555e4624dedab01b76102a3bdf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a11f6a10d0940dfa77b2c64f72cf07d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a36e3010aa4646addc93fae6e6cdbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6d5e3cd8b947dd91912d44317eae73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07109de39aab446fad5139821fa5b29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0bac70ec80f41b58a9881633e9f1b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb802895fb6f4ec6b8b61c29fd1a6fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# model_name = 'meta-llama/Meta-Llama-3.1-8B'\n",
    "model_name = 'meta-llama/Llama-2-7b-hf'\n",
    "base_model = './original_model/'\n",
    "snapshot_download(repo_id=model_name,local_dir=base_model,ignore_patterns=[\"*.pth\"],token=token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
